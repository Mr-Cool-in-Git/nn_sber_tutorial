{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Для датасета животных обучить MLP\n",
    "2. Использовать Custom Dataset, Sampler, collate_fn\n",
    "3. Сделать предобработку фичей\n",
    "4. Попробовать BatchNorm1d, Dropout\n",
    "4. Подключить для логирования tensorboard и/или mlflow\n",
    "5. Не забыть разделить выборку на train/valid в соотношении 80/20%\n",
    "6. Получить точность не ниже 65%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, Sampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Board\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "train_writer = SummaryWriter('./logs/train')\n",
    "valid_writer = SummaryWriter('./logs/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 36\n",
    "HIDDEN_SIZE = 25\n",
    "OUTPUT_SIZE = 5\n",
    "LEARNING_RATE = 1e-2\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "EMBEDDING_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    # Конструктор, где считаем датасет\n",
    "    def __init__(self):\n",
    "        X = pd.read_csv('./data/X_cat.csv', sep='\\t', index_col=0)\n",
    "        target = pd.read_csv('./data/y_cat.csv', sep='\\t', index_col=0, names=['status'])  # header=-1,\n",
    "\n",
    "        weekday_columns = ['Weekday_0', 'Weekday_1', 'Weekday_2',\n",
    "                           'Weekday_3', 'Weekday_4', 'Weekday_5', 'Weekday_6']\n",
    "        weekdays = np.argmax(X[weekday_columns].values, axis=1)\n",
    "\n",
    "        X.drop(weekday_columns, axis=1, inplace=True)\n",
    "\n",
    "        \n",
    "        X['Weekday_cos'] = np.cos(2 * np.pi / 7.) * weekdays\n",
    "        X['Weekday_sin'] = np.sin(2 * np.pi / 7.) * weekdays\n",
    "\n",
    "        X['Hour_cos'] = np.cos(2 * np.pi / 24.) * X['Hour'].values\n",
    "        X['Hour_sin'] = np.sin(2 * np.pi / 24.) * X['Hour'].values\n",
    "\n",
    "        X['Month_cos'] = np.cos(2 * np.pi / 12.) * X['Month'].values\n",
    "        X['Month_sin'] = np.sin(2 * np.pi / 12.) * X['Month'].values\n",
    "\n",
    "        X['Gender'] = np.argmax(X[['Sex_Female', 'Sex_Male', 'Sex_Unknown']].values, axis=1)\n",
    "        \n",
    "        X['Age'] = X['Age'].apply(lambda x: 0 if x <= 350 else 1 if x <= 800 else 2 if x<=2000 else 3)\n",
    "\n",
    "        X.drop(['Sex_Female', 'Sex_Male', 'Sex_Unknown'], axis=1, inplace=True)\n",
    "\n",
    "        #print(X.shape)\n",
    "        #print(X.head())\n",
    "\n",
    "        target = target.iloc[:, :].values\n",
    "        target[target == 'Died'] = 'Euthanasia'\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        le.fit(target)\n",
    "        \n",
    "        X,_,target,_= train_test_split(X,target, train_size=0.8,random_state=0)\n",
    "\n",
    "        self.y = le.transform(target)\n",
    "        self.X = X.values\n",
    "\n",
    "        self.columns = X.columns.values\n",
    "\n",
    "        self.embedding_column = 'Gender'\n",
    "        self.nrof_emb_categories = 3\n",
    "        self.numeric_columns = ['IsDog', 'Age', 'HasName', 'NameLength', 'NameFreq', 'MixColor', 'ColorFreqAsIs',\n",
    "                                'ColorFreqBase', 'TabbyColor', 'MixBreed', 'Domestic', 'Shorthair', 'Longhair',\n",
    "                                'Year', 'Day',  'Breed_Chihuahua Shorthair Mix', 'Breed_Domestic Medium Hair Mix',\n",
    "                                'Breed_Domestic Shorthair Mix', 'Breed_German Shepherd Mix', 'Breed_Labrador Retriever Mix',\n",
    "                                 'Breed_Pit Bull Mix', 'Breed_Rare',\n",
    "                                'SexStatus_Flawed', 'SexStatus_Intact', 'SexStatus_Unknown',\n",
    "                                'Weekday_cos', 'Weekday_sin', 'Hour_cos', 'Hour_sin',\n",
    "                                'Month_cos', 'Month_sin']\n",
    "        \n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    # Переопределяем метод,\n",
    "    # который достает по индексу наблюдение из датасет\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.X[idx, :]\n",
    "\n",
    "        row = {col: torch.tensor(row[i]) for i, col in enumerate(self.columns)}\n",
    "\n",
    "        return row, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidDataset(Dataset):\n",
    "    # Конструктор, где считаем датасет\n",
    "    def __init__(self):\n",
    "        X = pd.read_csv('./data/X_cat.csv', sep='\\t', index_col=0)\n",
    "        target = pd.read_csv('./data/y_cat.csv', sep='\\t', index_col=0, names=['status'])  # header=-1,\n",
    "\n",
    "        weekday_columns = ['Weekday_0', 'Weekday_1', 'Weekday_2',\n",
    "                           'Weekday_3', 'Weekday_4', 'Weekday_5', 'Weekday_6']\n",
    "        weekdays = np.argmax(X[weekday_columns].values, axis=1)\n",
    "\n",
    "        X.drop(weekday_columns, axis=1, inplace=True)\n",
    "\n",
    "        \n",
    "        X['Weekday_cos'] = np.cos(2 * np.pi / 7.) * weekdays\n",
    "        X['Weekday_sin'] = np.sin(2 * np.pi / 7.) * weekdays\n",
    "\n",
    "        X['Hour_cos'] = np.cos(2 * np.pi / 24.) * X['Hour'].values\n",
    "        X['Hour_sin'] = np.sin(2 * np.pi / 24.) * X['Hour'].values\n",
    "\n",
    "        X['Month_cos'] = np.cos(2 * np.pi / 12.) * X['Month'].values\n",
    "        X['Month_sin'] = np.sin(2 * np.pi / 12.) * X['Month'].values\n",
    "\n",
    "        X['Gender'] = np.argmax(X[['Sex_Female', 'Sex_Male', 'Sex_Unknown']].values, axis=1)\n",
    "        \n",
    "        X['Age'] = X['Age'].apply(lambda x: 0 if x <= 350 else 1 if x <= 800 else 2 if x<=2000 else 3)\n",
    "\n",
    "        X.drop(['Sex_Female', 'Sex_Male', 'Sex_Unknown'], axis=1, inplace=True)\n",
    "        \n",
    "        X,_,target,_= train_test_split(X,target, train_size=0.8,random_state=0)\n",
    "        \n",
    "\n",
    "        target = target.iloc[:, :].values\n",
    "        target[target == 'Died'] = 'Euthanasia'\n",
    "\n",
    "        le = LabelEncoder()\n",
    "        le.fit(target)\n",
    "        \n",
    "        _,X,_,target= train_test_split(X,target, train_size=0.8,random_state=0)\n",
    "\n",
    "        self.y = le.transform(target)\n",
    "        self.X = X.values\n",
    "\n",
    "        self.columns = X.columns.values\n",
    "\n",
    "        self.embedding_column = 'Gender'\n",
    "        self.nrof_emb_categories = 3\n",
    "        self.numeric_columns = ['IsDog', 'Age', 'HasName', 'NameLength', 'NameFreq', 'MixColor', 'ColorFreqAsIs',\n",
    "                                'ColorFreqBase', 'TabbyColor', 'MixBreed', 'Domestic', 'Shorthair', 'Longhair',\n",
    "                                'Year', 'Day',  'Breed_Chihuahua Shorthair Mix', 'Breed_Domestic Medium Hair Mix',\n",
    "                                'Breed_Domestic Shorthair Mix', 'Breed_German Shepherd Mix', 'Breed_Labrador Retriever Mix',\n",
    "                                 'Breed_Pit Bull Mix', 'Breed_Rare',\n",
    "                                'SexStatus_Flawed', 'SexStatus_Intact', 'SexStatus_Unknown',\n",
    "                                'Weekday_cos', 'Weekday_sin', 'Hour_cos', 'Hour_sin',\n",
    "                                'Month_cos', 'Month_sin']\n",
    "        \n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    # Переопределяем метод,\n",
    "    # который достает по индексу наблюдение из датасет\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        row = self.X[idx, :]\n",
    "\n",
    "        row = {col: torch.tensor(row[i]) for i, col in enumerate(self.columns)}\n",
    "\n",
    "        return row, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, output_size, nrof_cat, emb_dim,\n",
    "                 emb_columns, numeric_columns):\n",
    "        super(MLPNet, self).__init__()\n",
    "        self.emb_columns = emb_columns\n",
    "        self.numeric_columns = numeric_columns\n",
    "\n",
    "        self.emb_layer = torch.nn.Embedding(nrof_cat, emb_dim)\n",
    "\n",
    "        self.feature_bn = torch.nn.BatchNorm1d(input_size)\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.linear1.apply(self.init_weights)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "        self.linear2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear2.apply(self.init_weights)\n",
    "        self.dp2 = torch.nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "        self.linear3 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3.apply(self.init_weights)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(hidden_size)\n",
    "\n",
    "        self.linear4 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def init_weights(self, m):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb_output = self.emb_layer(torch.tensor(x[self.emb_columns], dtype=torch.int64))\n",
    "        numeric_feats = torch.tensor(pd.DataFrame(x)[self.numeric_columns].values, dtype=torch.float32)\n",
    "\n",
    "        concat_input = torch.cat([numeric_feats, emb_output], dim=1)\n",
    "        output = self.feature_bn(concat_input)\n",
    "\n",
    "        output = self.linear1(output)\n",
    "        output = self.bn1(output)\n",
    "        output = torch.relu(output)\n",
    "        \n",
    "        output = self.linear2(output)\n",
    "        output = self.dp2(output)\n",
    "        output = torch.relu(output)\n",
    "\n",
    "        output = self.linear3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = torch.relu(output)\n",
    "\n",
    "        output = self.linear4(output)\n",
    "        predictions = torch.softmax(output, dim=1)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(model, train_loader, valid_loader):\n",
    "    step = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "\n",
    "        for features, label in train_loader:\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(features)\n",
    "            # Calculate error and backpropagate\n",
    "            loss = criterion(output, label.type(torch.LongTensor))\n",
    "            loss.backward()\n",
    "            acc = accuracy(output, label.type(torch.LongTensor)).item()\n",
    "            \n",
    "            # Update weights with gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            step += 1\n",
    "\n",
    "            if step % 100 == 0:\n",
    "                print('EPOCH %d STEP %d : train_loss: %f train_acc: %f' %\n",
    "                      (epoch, step, loss.item(), acc))\n",
    "                \n",
    "        train_writer.add_scalar('CrossEntropyLoss', loss, epoch)\n",
    "        train_writer.add_scalar('Accuracy', acc, epoch)\n",
    "                \n",
    "        for features, label in valid_loader:\n",
    "                    \n",
    "            output = model(features)\n",
    "            loss = criterion(output, label.type(torch.LongTensor))\n",
    "            acc = accuracy(output, label.type(torch.LongTensor)).item()\n",
    "            step += 1\n",
    "            \n",
    "        valid_writer.add_scalar('CrossEntropyLoss', loss, epoch)\n",
    "        valid_writer.add_scalar('Accuracy', acc, epoch)\n",
    "\n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch):\n",
    "    return default_collate(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26729, 34)\n",
      "   IsDog  Age  HasName  NameLength  NameFreq  MixColor  ColorFreqAsIs  \\\n",
      "0      1    1        1           7  0.000157         1       0.032919   \n",
      "1      0    1        1           5  0.000655         0       0.008092   \n",
      "2      1    1        1           6  0.000052         1       0.026293   \n",
      "3      0    0        0           7  0.285871         0       0.000471   \n",
      "4      1    1        0           7  0.285871         0       0.023831   \n",
      "\n",
      "   ColorFreqBase  TabbyColor  MixBreed  ...  SexStatus_Flawed  \\\n",
      "0       0.463624           0         1  ...                 1   \n",
      "1       0.015005           1         1  ...                 1   \n",
      "2       0.357521           0         1  ...                 1   \n",
      "3       0.058418           0         1  ...                 0   \n",
      "4       0.075353           0         0  ...                 1   \n",
      "\n",
      "   SexStatus_Intact  SexStatus_Unknown  Weekday_cos  Weekday_sin   Hour_cos  \\\n",
      "0                 0                  0     1.246980     1.563663  13.877134   \n",
      "1                 0                  0     3.740939     4.690989   8.435752   \n",
      "2                 0                  0     3.117449     3.909157   9.144098   \n",
      "3                 1                  0     2.493959     3.127326  14.633776   \n",
      "4                 0                  0     2.493959     3.127326   8.564542   \n",
      "\n",
      "   Hour_sin  Month_cos  Month_sin  Gender  \n",
      "0  3.718367   1.732051        1.0       1  \n",
      "1  2.260353   8.660254        5.0       0  \n",
      "2  2.450154   0.866025        0.5       1  \n",
      "3  3.921109   6.062178        3.5       1  \n",
      "4  2.294862   9.526279        5.5       1  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# Пример Loader с Sampler\n",
    "animal_dataset = CustomDataset()\n",
    "sampler = Sampler(animal_dataset)\n",
    "sampled_loader = data_utils.DataLoader(dataset=animal_dataset, sampler=sampler, collate_fn=collate,\n",
    "                                     batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26729, 34)\n",
      "   IsDog  Age  HasName  NameLength  NameFreq  MixColor  ColorFreqAsIs  \\\n",
      "0      1    1        1           7  0.000157         1       0.032919   \n",
      "1      0    1        1           5  0.000655         0       0.008092   \n",
      "2      1    1        1           6  0.000052         1       0.026293   \n",
      "3      0    0        0           7  0.285871         0       0.000471   \n",
      "4      1    1        0           7  0.285871         0       0.023831   \n",
      "\n",
      "   ColorFreqBase  TabbyColor  MixBreed  ...  SexStatus_Flawed  \\\n",
      "0       0.463624           0         1  ...                 1   \n",
      "1       0.015005           1         1  ...                 1   \n",
      "2       0.357521           0         1  ...                 1   \n",
      "3       0.058418           0         1  ...                 0   \n",
      "4       0.075353           0         0  ...                 1   \n",
      "\n",
      "   SexStatus_Intact  SexStatus_Unknown  Weekday_cos  Weekday_sin   Hour_cos  \\\n",
      "0                 0                  0     1.246980     1.563663  13.877134   \n",
      "1                 0                  0     3.740939     4.690989   8.435752   \n",
      "2                 0                  0     3.117449     3.909157   9.144098   \n",
      "3                 1                  0     2.493959     3.127326  14.633776   \n",
      "4                 0                  0     2.493959     3.127326   8.564542   \n",
      "\n",
      "   Hour_sin  Month_cos  Month_sin  Gender  \n",
      "0  3.718367   1.732051        1.0       1  \n",
      "1  2.260353   8.660254        5.0       0  \n",
      "2  2.450154   0.866025        0.5       1  \n",
      "3  3.921109   6.062178        3.5       1  \n",
      "4  2.294862   9.526279        5.5       1  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "animal_dataset = CustomDataset()\n",
    "\n",
    "train_dataset = TrainDataset()\n",
    "valid_dataset = ValidDataset()\n",
    "\n",
    "train_loader = data_utils.DataLoader(dataset=train_dataset, shuffle=True,\n",
    "                                     batch_size=BATCH_SIZE)\n",
    "valid_loader = data_utils.DataLoader(dataset=valid_dataset, shuffle=True,\n",
    "                                     batch_size=BATCH_SIZE)\n",
    "\n",
    "model = MLPNet(INPUT_SIZE, HIDDEN_SIZE, OUTPUT_SIZE, animal_dataset.nrof_emb_categories,\n",
    "               EMBEDDING_SIZE,\n",
    "               animal_dataset.embedding_column, animal_dataset.numeric_columns)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "accuracy = Accuracy()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 16 STEP 1700 : train_loss: 1.180318 train_acc: 0.718518\n",
      "EPOCH 17 STEP 1800 : train_loss: 1.222556 train_acc: 0.675781\n",
      "EPOCH 18 STEP 1900 : train_loss: 1.278427 train_acc: 0.609375\n",
      "EPOCH 19 STEP 2000 : train_loss: 1.199100 train_acc: 0.707031\n",
      "EPOCH 20 STEP 2100 : train_loss: 1.194548 train_acc: 0.707031\n",
      "EPOCH 21 STEP 2200 : train_loss: 1.279716 train_acc: 0.621094\n",
      "EPOCH 22 STEP 2300 : train_loss: 1.280003 train_acc: 0.613281\n",
      "EPOCH 23 STEP 2400 : train_loss: 1.199502 train_acc: 0.695312\n",
      "EPOCH 24 STEP 2500 : train_loss: 1.256261 train_acc: 0.636719\n",
      "EPOCH 25 STEP 2600 : train_loss: 1.230916 train_acc: 0.660156\n",
      "EPOCH 26 STEP 2700 : train_loss: 1.202373 train_acc: 0.695312\n",
      "EPOCH 27 STEP 2800 : train_loss: 1.173871 train_acc: 0.722656\n",
      "EPOCH 28 STEP 2900 : train_loss: 1.209973 train_acc: 0.699219\n",
      "EPOCH 29 STEP 3000 : train_loss: 1.242350 train_acc: 0.656250\n",
      "EPOCH 30 STEP 3100 : train_loss: 1.205398 train_acc: 0.695312\n",
      "EPOCH 31 STEP 3200 : train_loss: 1.225600 train_acc: 0.675781\n",
      "EPOCH 32 STEP 3300 : train_loss: 1.264280 train_acc: 0.632812\n",
      "EPOCH 33 STEP 3400 : train_loss: 1.212833 train_acc: 0.695312\n",
      "EPOCH 34 STEP 3500 : train_loss: 1.205000 train_acc: 0.695312\n",
      "EPOCH 35 STEP 3600 : train_loss: 1.191082 train_acc: 0.707031\n",
      "EPOCH 36 STEP 3700 : train_loss: 1.187152 train_acc: 0.714844\n",
      "EPOCH 37 STEP 3800 : train_loss: 1.192748 train_acc: 0.714844\n",
      "EPOCH 38 STEP 3900 : train_loss: 1.184878 train_acc: 0.722656\n",
      "EPOCH 39 STEP 4000 : train_loss: 1.172066 train_acc: 0.726562\n",
      "EPOCH 40 STEP 4100 : train_loss: 1.236903 train_acc: 0.660156\n",
      "EPOCH 41 STEP 4200 : train_loss: 1.224719 train_acc: 0.683594\n",
      "EPOCH 42 STEP 4300 : train_loss: 1.216489 train_acc: 0.695312\n",
      "EPOCH 43 STEP 4400 : train_loss: 1.297523 train_acc: 0.605469\n",
      "EPOCH 44 STEP 4500 : train_loss: 1.190520 train_acc: 0.710938\n",
      "EPOCH 45 STEP 4600 : train_loss: 1.221764 train_acc: 0.679688\n",
      "EPOCH 46 STEP 4700 : train_loss: 1.204375 train_acc: 0.695312\n",
      "EPOCH 47 STEP 4800 : train_loss: 1.167602 train_acc: 0.738281\n",
      "EPOCH 48 STEP 4900 : train_loss: 1.181356 train_acc: 0.714844\n",
      "EPOCH 49 STEP 5000 : train_loss: 1.268190 train_acc: 0.632812\n"
     ]
    }
   ],
   "source": [
    "step = run_train(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sampler(animal_dataset):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
